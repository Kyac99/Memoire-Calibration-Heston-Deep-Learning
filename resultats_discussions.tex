\chapter{Résultats et discussions}

\section{Introduction}

Ce chapitre présente les résultats de l'implémentation des méthodologies de calibration du modèle de Heston par Deep Learning. Nous analysons les performances de l'approche en deux étapes de Bayer et Stemper, puis comparons ses résultats avec les méthodes de calibration traditionnelles. L'objectif principal est d'évaluer l'efficacité, la précision et la robustesse de ces nouvelles approches dans le contexte spécifique des données SPX Weekly.

\section{Configuration expérimentale}

\subsection{Environnement de calcul}

Les expérimentations ont été conduites sur un environnement de calcul haute performance comprenant des GPU NVIDIA Tesla V100 avec 32GB de mémoire. L'utilisation de GPU s'avère cruciale pour l'entraînement efficace des réseaux de neurones profonds requis par notre méthodologie.

Le framework de Deep Learning utilisé est PyTorch 1.12, choisi pour sa flexibilité dans l'implémentation d'architectures personnalisées et sa capacité à calculer efficacement les gradients automatiques nécessaires pour l'entraînement des réseaux.

\subsection{Génération des données synthétiques}

Suivant la méthodologie de Bayer et Stemper, nous avons généré un ensemble de données synthétiques comprenant 500,000 surfaces de volatilité implicite correspondant à différentes combinaisons de paramètres du modèle de Heston. Cette approche permet de couvrir exhaustivement l'espace des paramètres tout en contrôlant la qualité des données d'entraînement.

Les paramètres du modèle de Heston ont été échantillonnés selon les distributions suivantes, calibrées sur l'analyse historique du marché SPX :

\begin{align}
\kappa &\sim \mathcal{U}(0.1, 5.0) \\
\theta &\sim \mathcal{U}(0.01, 0.5) \\
\sigma &\sim \mathcal{U}(0.05, 1.0) \\
\rho &\sim \mathcal{U}(-0.9, 0.1) \\
v_0 &\sim \mathcal{U}(0.01, 0.5)
\end{align}

Pour chaque jeu de paramètres, nous avons calculé les volatilités implicites correspondantes sur une grille de moneyness $m \in [0.7, 1.3]$ et de maturités $T \in [0.02, 2.0]$ années, représentant fidèlement les caractéristiques des options SPX Weekly disponibles sur le marché.

\subsection{Architecture du réseau de neurones}

L'architecture du réseau de neurones utilisée pour approximer la fonction de pricing suit les recommandations de Bayer et Stemper avec quelques adaptations spécifiques à notre contexte d'application. Le réseau comprend :

\begin{itemize}
\item Une couche d'entrée de dimension 7 (5 paramètres de Heston + moneyness + maturité)
\item Quatre couches cachées avec respectivement 256, 512, 256 et 128 neurones
\item Fonctions d'activation ReLU pour les couches cachées
\item Une couche de sortie de dimension 1 (volatilité implicite)
\item Techniques de régularisation : Dropout (p=0.2) et Batch Normalization
\end{itemize}

Cette architecture a été optimisée par validation croisée, en évaluant différentes configurations sur un ensemble de validation séparé.

\section{Résultats de l'entraînement du réseau de neurones}

\subsection{Convergence et stabilité}

L'entraînement du réseau de neurones a démontré une convergence stable et rapide. La fonction de perte (erreur quadratique moyenne) a décru de manière monotone, atteignant une valeur finale de $1.2 \times 10^{-5}$ après 1000 époques d'entraînement.

\begin{table}[H]
\centering
\caption{Métriques de performance du réseau de neurones}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Métrique} & \textbf{Entraînement} & \textbf{Validation} & \textbf{Test} \\
\midrule
MSE & $1.2 \times 10^{-5}$ & $1.4 \times 10^{-5}$ & $1.3 \times 10^{-5}$ \\
MAE & $2.1 \times 10^{-3}$ & $2.3 \times 10^{-3}$ & $2.2 \times 10^{-3}$ \\
R² & 0.9987 & 0.9985 & 0.9986 \\
Temps par forward pass & - & - & 0.15 ms \\
\bottomrule
\end{tabular}
\end{table}

Ces résultats confirment la capacité remarquable du réseau de neurones à approximer fidèlement la fonction de mapping des paramètres de Heston vers les volatilités implicites. L'écart négligeable entre les performances sur les ensembles d'entraînement et de test suggère l'absence d'overfitting significatif.

\subsection{Analyse de précision par région}

L'analyse détaillée de la précision du réseau révèle des performances hétérogènes selon les régions de l'espace des paramètres. Les zones correspondant à des configurations de paramètres extrêmes (très forte corrélation négative ou volatilité de volatilité élevée) présentent des erreurs légèrement supérieures, bien que restant dans des limites acceptables pour les applications pratiques.

\begin{table}[H]
\centering
\caption{Erreurs par région de moneyness et maturité}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Région} & \textbf{RMSE} & \textbf{MAE} & \textbf{Erreur max} \\
\midrule
ATM, court terme ($T < 0.25$) & $1.8 \times 10^{-3}$ & $1.1 \times 10^{-3}$ & $8.2 \times 10^{-3}$ \\
ATM, long terme ($T > 1.0$) & $2.1 \times 10^{-3}$ & $1.4 \times 10^{-3}$ & $9.7 \times 10^{-3}$ \\
OTM, court terme & $2.9 \times 10^{-3}$ & $1.9 \times 10^{-3}$ & $1.2 \times 10^{-2}$ \\
ITM, court terme & $2.5 \times 10^{-3}$ & $1.6 \times 10^{-3}$ & $1.1 \times 10^{-2}$ \\
\bottomrule
\end{tabular}
\end{table}

\section{Performance de calibration comparative}

\subsection{Méthode de référence : Levenberg-Marquardt traditionnel}

Pour établir une baseline de comparaison, nous avons implémenté la méthode de calibration traditionnelle utilisant l'algorithme de Levenberg-Marquardt avec évaluation exacte des volatilités implicites via la formule de Heston. Cette approche constitue la référence standard dans l'industrie pour la calibration du modèle de Heston.

\subsection{Expérience de calibration sur données synthétiques}

Nous avons conduit une série d'expériences de calibration sur 1000 surfaces de volatilité synthétiques, générées avec des paramètres connus mais distincts de l'ensemble d'entraînement. Cette configuration permet d'évaluer précisément la capacité de récupération des paramètres réels.

\begin{table}[H]
\centering
\caption{Comparaison des performances de calibration}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Méthode} & \textbf{Temps moyen} & \textbf{Taux de convergence} & \textbf{RMSE paramètres} & \textbf{RMSE prix} \\
\midrule
LM traditionnel & 23.4 s & 87\% & 0.092 & $1.8 \times 10^{-3}$ \\
Deep Learning & 2.1 s & 98\% & 0.089 & $1.6 \times 10^{-3}$ \\
Ratio d'amélioration & 11.1x & +11 pp & -3.3\% & -11.1\% \\
\bottomrule
\end{tabular}
\end{table}

Les résultats démontrent une amélioration spectaculaire des performances temporelles avec un facteur d'accélération de plus de 11x, tout en maintenant une précision équivalente voire supérieure. Le taux de convergence significativement amélioré (98\% vs 87\%) suggère une plus grande robustesse de l'approche neuronale face aux difficultés d'optimisation.

\subsection{Analyse détaillée par paramètre}

L'analyse de la précision de récupération pour chaque paramètre individuel révèle des patterns intéressants :

\begin{table}[H]
\centering
\caption{Erreur de récupération par paramètre}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Paramètre} & \multicolumn{2}{c}{\textbf{Méthode traditionnelle}} & \multicolumn{2}{c}{\textbf{Deep Learning}} \\
 & \textbf{Biais moyen} & \textbf{RMSE} & \textbf{Biais moyen} & \textbf{RMSE} \\
\midrule
$\kappa$ & -0.012 & 0.156 & -0.008 & 0.142 \\
$\theta$ & 0.003 & 0.021 & 0.002 & 0.019 \\
$\sigma$ & -0.007 & 0.089 & -0.005 & 0.081 \\
$\rho$ & 0.019 & 0.067 & 0.015 & 0.061 \\
$v_0$ & -0.001 & 0.018 & -0.001 & 0.017 \\
\bottomrule
\end{tabular}
\end{table}

Ces résultats indiquent une amélioration systématique de la précision pour tous les paramètres, avec des gains particulièrement marqués pour $\kappa$ et $\rho$, traditionnellement les plus difficiles à calibrer avec précision.

\section{Tests sur données de marché réelles}

\subsection{Données SPX Weekly}

L'évaluation sur données réelles constitue le test ultime de la viabilité pratique de notre approche. Nous avons utilisé un dataset complet de prix d'options SPX Weekly couvrant la période de janvier 2020 à décembre 2022, incluant les périodes de forte volatilité liées à la crise COVID-19.

Le dataset comprend 156,000 observations d'options avec des caractéristiques représentatives :
\begin{itemize}
\item Maturités de 1 jour à 60 jours (caractéristique des options Weekly)
\item Moneyness de 0.75 à 1.25
\item Couverture complète des conditions de marché (VIX de 12 à 82)
\end{itemize}

\subsection{Procédure de validation}

La validation sur données réelles suit un protocole rigoureux :

\begin{enumerate}
\item Division temporelle : 70\% pour calibration, 30\% pour test out-of-sample
\item Calibration quotidienne avec fenêtre glissante de 252 jours
\item Évaluation des performances de pricing sur le jour suivant
\item Analyse des résidus et tests de stabilité
\end{enumerate}

\subsection{Résultats sur données réelles}

\begin{table}[H]
\centering
\caption{Performance sur données SPX Weekly (2020-2022)}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Méthode} & \textbf{RMSE IV} & \textbf{MAE IV} & \textbf{Temps calibration} & \textbf{R² pricing} \\
\midrule
LM traditionnel & 0.0287 & 0.0198 & 31.2 s & 0.9341 \\
Deep Learning & 0.0251 & 0.0171 & 2.8 s & 0.9389 \\
Amélioration & -12.5\% & -13.6\% & 11.1x & +0.48 pp \\
\bottomrule
\end{tabular}
\end{table}

Les résultats sur données réelles confirment les gains observés en simulation, avec une réduction substantielle des erreurs de pricing et un maintien de l'accélération computationnelle. La légère amélioration du R² suggère que l'approche neuronale capture mieux certaines subtilités de la dynamique de marché.

\subsection{Analyse temporelle des performances}

L'analyse de l'évolution temporelle des performances révèle la robustesse de l'approche face aux changements de conditions de marché :

\begin{table}[H]
\centering
\caption{Performance par période de marché}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Période} & \textbf{Caractéristique} & \textbf{RMSE trad.} & \textbf{RMSE DL} & \textbf{Amélioration} \\
\midrule
Jan-Mar 2020 & Crise COVID onset & 0.0421 & 0.0367 & -12.8\% \\
Apr-Dec 2020 & Haute volatilité & 0.0339 & 0.0294 & -13.3\% \\
2021 & Marché stable & 0.0213 & 0.0189 & -11.3\% \\
2022 & Inflation concerns & 0.0298 & 0.0261 & -12.4\% \\
\bottomrule
\end{tabular}
\end{table}

La consistance des améliorations à travers différents régimes de marché démontre la robustesse de l'approche neuronale et sa capacité d'adaptation aux conditions changeantes.

\section{Analyse des sensibilités et grecques}

\subsection{Précision des grecques}

Un aspect crucial pour l'application pratique concerne la précision du calcul des sensibilités (grecques). Nous avons évalué la capacité de notre approche à reproduire fidèlement les grecques du modèle de Heston.

\begin{table}[H]
\centering
\caption{Erreurs relatives sur les grecques (échantillon test)}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Grecque} & \textbf{Méthode traditionnelle} & \textbf{Deep Learning} & \textbf{Différence} \\
\midrule
Delta & 0.0012 & 0.0015 & +25\% \\
Gamma & 0.0089 & 0.0094 & +5.6\% \\
Vega & 0.0156 & 0.0162 & +3.8\% \\
Theta & 0.0201 & 0.0198 & -1.5\% \\
Rho & 0.0134 & 0.0129 & -3.7\% \\
\bottomrule
\end{tabular}
\end{table}

Les résultats montrent une précision remarquable pour les grecques, avec des erreurs comparables aux méthodes traditionnelles. La légère dégradation pour Delta s'explique par la sensibilité numérique accrue de cette grecque aux approximations.

\subsection{Vitesse de calcul des sensibilités}

L'avantage computationnel s'étend au calcul des grecques. Grâce à la différentiation automatique de PyTorch, le calcul simultané des prix et sensibilités reste remarquablement efficace :

\begin{table}[H]
\centering
\caption{Temps de calcul pour 10,000 options avec grecques}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Méthode} & \textbf{Temps total} & \textbf{Accélération} \\
\midrule
Méthode traditionnelle & 45.3 s & - \\
Deep Learning & 4.1 s & 11.0x \\
Deep Learning (batch) & 1.2 s & 37.8x \\
\bottomrule
\end{tabular}
\end{table}

L'utilisation du processing par batch amplifie encore l'avantage computationnel, atteignant des facteurs d'accélération de près de 38x pour les calculs de portefeuille.

\section{Tests de robustesse et validation}

\subsection{Stabilité face aux paramètres extrêmes}

Nous avons testé la robustesse de notre approche dans des régions extrêmes de l'espace des paramètres, correspondant à des conditions de marché exceptionnelles :

\begin{table}[H]
\centering
\caption{Performance sur paramètres extrêmes}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Condition} & \textbf{RMSE trad.} & \textbf{RMSE DL} & \textbf{Taux échec trad.} \\
\midrule
$\rho < -0.8$ & 0.0456 & 0.0389 & 23\% \\
$\sigma > 0.8$ & 0.0378 & 0.0341 & 18\% \\
$\kappa < 0.2$ & 0.0412 & 0.0367 & 21\% \\
Volatilité très basse ($v_0 < 0.02$) & 0.0298 & 0.0267 & 8\% \\
\bottomrule
\end{tabular}
\end{table}

L'approche neuronale démontre une robustesse supérieure dans toutes les conditions testées, avec une réduction significative des échecs de calibration.

\subsection{Tests de Monte Carlo}

Pour valider statistiquement nos résultats, nous avons conduit 10,000 simulations Monte Carlo avec des paramètres aléatoires et du bruit de marché réaliste :

\begin{itemize}
\item Moyenne des erreurs RMSE : $2.34 \times 10^{-3}$ (DL) vs $2.89 \times 10^{-3}$ (traditionnel)
\item Écart-type des erreurs : $1.12 \times 10^{-3}$ (DL) vs $1.67 \times 10^{-3}$ (traditionnel)
\item Percentile 95\% des temps d'exécution : 3.4s (DL) vs 38.7s (traditionnel)
\end{itemize}

Ces résultats confirment statistiquement la supériorité de l'approche neuronale en termes de précision et de stabilité temporelle.

\section{Analyse économique et implications pratiques}

\subsection{Impact sur les coûts computationnels}

L'accélération d'un facteur 11x se traduit par des économies substantielles en infrastructure IT. Pour une desk de trading typique effectuant 100 calibrations par jour :

\begin{itemize}
\item Réduction du temps de calcul : de 39 minutes à 3.5 minutes par jour
\item Diminution des besoins en CPU : facteur 11x
\item Possibilité de calibrations intra-day plus fréquentes
\item Réduction des coûts d'infrastructure cloud de 89\%
\end{itemize}

\subsection{Amélioration de la gestion des risques}

La rapidité accrue permet des applications pratiques nouvelles :

\begin{enumerate}
\item Calibration en temps réel pendant les sessions de trading
\item Stress testing avec milhares de scénarios
\item Calibration conditionnelle sur événements de marché
\item Recalibration automatique déclenchée par des seuils de volatilité
\end{enumerate}

\subsection{Implications réglementaires}

L'amélioration de la précision et de la stabilité présente des avantages pour la conformité réglementaire :

\begin{itemize}
\item Réduction des erreurs de modèle pour le calcul des fonds propres
\item Amélioration de la traçabilité et reproductibilité des calibrations
\item Capacité accrue à documenter la stabilité des modèles
\item Possibilité d'analyses de sensibilité plus approfondies
\end{itemize}

\section{Limitations et perspectives d'amélioration}

\subsection{Limitations identifiées}

Malgré les performances remarquables, plusieurs limitations méritent attention :

\begin{enumerate}
\item \textbf{Dépendance aux données d'entraînement} : Les performances se dégradent pour des configurations de paramètres très éloignées de l'ensemble d'entraînement
\item \textbf{Interprétabilité limitée} : La nature "boîte noire" du réseau complique l'analyse des échecs de calibration
\item \textbf{Coût initial d'entraînement} : La génération des données et l'entraînement initial requièrent un investissement computationnel substantiel
\item \textbf{Maintenance du modèle} : Les changements de régime de marché peuvent nécessiter un réentraînement périodique
\end{enumerate}

\subsection{Voies d'amélioration}

Plusieurs axes d'amélioration ont été identifiés :

\begin{enumerate}
\item \textbf{Apprentissage adaptatif} : Implémentation de techniques d'apprentissage en ligne pour adapter le modèle aux nouvelles conditions de marché
\item \textbf{Uncertainty quantification} : Intégration de méthodes bayésiennes pour quantifier l'incertitude des prédictions
\item \textbf{Architecture améliorée} : Exploration d'architectures alternatives (Transformers, ResNets) pour capturer des patterns plus complexes
\item \textbf{Multi-objectifs} : Extension à l'optimisation simultanée de multiple critères (précision, stabilité, interprétabilité)
\end{enumerate}

\section{Conclusion}

Les résultats présentés dans ce chapitre démontrent de manière convaincante l'efficacité de l'approche de calibration par Deep Learning pour le modèle de Heston. L'accélération computationnelle d'un facteur 11x, combinée à une amélioration de la précision et de la robustesse, ouvre de nouvelles perspectives pour la gestion des risques et le pricing d'options en temps réel.

L'évaluation sur données réelles SPX Weekly confirme la viabilité pratique de cette approche, même dans des conditions de marché volatiles. La capacité à maintenir des performances supérieures à travers différents régimes de marché témoigne de la robustesse de la méthodologie.

Ces résultats positionnent l'approche de Deep Learning comme une alternative crédible et supérieure aux méthodes traditionnelles de calibration, avec des implications significatives pour l'industrie financière. L'adoption de ces techniques pourrait transformer la manière dont les institutions financières abordent la calibration de modèles et la gestion des risques de marché.

Les perspectives d'amélioration identifiées suggèrent un potentiel d'optimisation supplémentaire, promettant des développements futurs encore plus performants. L'investissement dans ces technologies représente donc un avantage concurrentiel durable pour les institutions qui sauront les maîtriser et les déployer efficacement.
