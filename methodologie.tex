\chapter{Méthodologie}

\section{Introduction méthodologique}

Ce chapitre présente en détail la méthodologie développée pour implémenter la calibration accélérée du modèle de Heston par Deep Learning. Notre approche s'appuie sur les travaux fondamentaux de \citet{bayer2018deep} tout en apportant des innovations spécifiques aux caractéristiques des données SPX Weekly et aux exigences de l'environnement de trading moderne.

La méthodologie adoptée suit une philosophie en deux étapes qui permet de concilier l'efficacité computationnelle du Deep Learning avec la robustesse des algorithmes d'optimisation traditionnels. Cette approche hybride présente l'avantage de préserver la transparence et la contrôlabilité des processus de calibration tout en bénéficiant des gains de performance spectaculaires offerts par les techniques d'apprentissage automatique.

\section{Le modèle de Heston : fondements mathématiques}

\subsection{Formulation du modèle}

Le modèle de Heston \citep{heston1993closed} décrit l'évolution conjointe du prix de l'actif sous-jacent $S_t$ et de sa variance instantanée $v_t$ sous la mesure risque-neutre selon le système d'équations différentielles stochastiques suivant :

\begin{align}
\frac{dS_t}{S_t} &= r dt + \sqrt{v_t} dW_t^{(1)} \label{eq:heston_price}\\
dv_t &= \kappa(\theta - v_t)dt + \sigma\sqrt{v_t}dW_t^{(2)} \label{eq:heston_variance}
\end{align}

où $dW_t^{(1)}$ et $dW_t^{(2)}$ sont des mouvements browniens corrélés satisfaisant :
\begin{equation}
d\langle W^{(1)}, W^{(2)} \rangle_t = \rho dt
\end{equation}

Les paramètres du modèle admettent les interprétations financières suivantes :

\begin{itemize}
\item $\kappa > 0$ : vitesse de retour à la moyenne de la variance
\item $\theta > 0$ : niveau de long terme de la variance
\item $\sigma > 0$ : volatilité de la volatilité (vol-of-vol)
\item $\rho \in [-1,1]$ : corrélation entre les innovations de prix et de variance
\item $v_0 > 0$ : variance initiale
\item $r$ : taux d'intérêt sans risque
\end{itemize}

\subsection{Conditions d'existence et propriétés}

Pour assurer l'existence et l'unicité de la solution, ainsi que la positivité presque sûre de la variance, la condition de Feller doit être satisfaite :

\begin{equation}
2\kappa\theta \geq \sigma^2 \label{eq:feller}
\end{equation}

Cette condition garantit que le processus de variance ne peut atteindre zéro, évitant ainsi les problèmes de définition de $\sqrt{v_t}$ dans l'équation (\ref{eq:heston_price}).

\subsection{Fonction caractéristique et pricing}

La fonction caractéristique du log-prix $X_t = \ln(S_t)$ sous le modèle de Heston admet une forme analytique explicite. Pour $\phi \in \mathbb{C}$, nous avons :

\begin{equation}
\Phi_T(\phi) = \mathbb{E}[e^{i\phi X_T}] = \exp(C(T,\phi) + D(T,\phi)v_0 + i\phi X_0)
\end{equation}

où les fonctions $C(T,\phi)$ et $D(T,\phi)$ sont définies par :

\begin{align}
C(T,\phi) &= r\phi iT + \frac{\kappa\theta}{\sigma^2}\left[(\kappa - \rho\sigma\phi i - d)T - 2\ln\left(\frac{1-ge^{-dT}}{1-g}\right)\right]\\
D(T,\phi) &= \frac{\kappa - \rho\sigma\phi i - d}{\sigma^2}\left(\frac{1-e^{-dT}}{1-ge^{-dT}}\right)
\end{align}

avec :
\begin{align}
d &= \sqrt{(\rho\sigma\phi i - \kappa)^2 - \sigma^2(-\phi i - \phi^2)}\\
g &= \frac{\kappa - \rho\sigma\phi i - d}{\kappa - \rho\sigma\phi i + d}
\end{align}

Cette fonction caractéristique permet le calcul efficace des prix d'options européennes via les techniques de transformation de Fourier développées par \citet{carr1999option}.

\subsection{Calcul de la volatilité implicite}

Pour une option européenne de strike $K$ et maturité $T$, le prix théorique $C^{Heston}$ calculé via la formule de Heston doit être inversé pour obtenir la volatilité implicite $\sigma_{IV}$ satisfaisant :

\begin{equation}
C^{Heston}(S_0, K, T, r, \boldsymbol{\theta}) = C^{BS}(S_0, K, T, r, \sigma_{IV})
\end{equation}

où $C^{BS}$ désigne la formule de Black-Scholes et $\boldsymbol{\theta} = (\kappa, \theta, \sigma, \rho, v_0)$ le vecteur des paramètres de Heston.

Cette inversion, typiquement réalisée par des méthodes de recherche de racine (Brent, Newton-Raphson), constitue une étape computationnellement coûteuse qui sera remplacée par notre approximation neuronale.

\section{Procédures de calibration traditionnelles}

\subsection{Formulation du problème d'optimisation}

La calibration traditionnelle du modèle de Heston consiste à résoudre le problème d'optimisation suivant :

\begin{equation}
\hat{\boldsymbol{\theta}} = \arg\min_{\boldsymbol{\theta} \in \Theta} \sum_{i=1}^{N} w_i \left(\sigma_{IV}^{market}(K_i, T_i) - \sigma_{IV}^{Heston}(K_i, T_i, \boldsymbol{\theta})\right)^2 \label{eq:calibration_objective}
\end{equation}

où :
\begin{itemize}
\item $N$ est le nombre d'options observées sur le marché
\item $w_i$ sont des poids reflétant la liquidité ou l'importance relative des options
\item $\Theta$ définit l'espace admissible des paramètres
\item $\sigma_{IV}^{market}(K_i, T_i)$ est la volatilité implicite observée
\item $\sigma_{IV}^{Heston}(K_i, T_i, \boldsymbol{\theta})$ est la volatilité implicite théorique
\end{itemize}

\subsection{Contraintes et bornes sur les paramètres}

L'espace de paramètres $\Theta$ est défini par des contraintes économiques et mathématiques :

\begin{align}
\Theta = \{(\kappa, \theta, \sigma, \rho, v_0) : &\; \kappa \in [0.01, 10], \\
&\; \theta \in [0.001, 1], \\
&\; \sigma \in [0.01, 2], \\
&\; \rho \in [-0.99, 0.5], \\
&\; v_0 \in [0.001, 1], \\
&\; 2\kappa\theta \geq \sigma^2\}
\end{align}

Ces bornes reflètent les observations empiriques sur les marchés d'options et garantissent la stabilité numérique des calculs.

\subsection{Algorithmes d'optimisation}

Plusieurs algorithmes d'optimisation peuvent être utilisés pour résoudre le problème (\ref{eq:calibration_objective}). Notre implémentation de référence utilise l'algorithme de Levenberg-Marquardt, particulièrement adapté aux problèmes de moindres carrés non linéaires.

L'algorithme de Levenberg-Marquardt combine les avantages de la méthode de Gauss-Newton et de la descente de gradient. À chaque itération $k$, la mise à jour des paramètres suit :

\begin{equation}
\boldsymbol{\theta}_{k+1} = \boldsymbol{\theta}_k - (J_k^T J_k + \lambda_k I)^{-1} J_k^T \boldsymbol{r}_k
\end{equation}

où $J_k$ est la matrice jacobienne des résidus, $\boldsymbol{r}_k$ le vecteur des résidus, et $\lambda_k$ le paramètre de régularisation adaptatif.

\subsection{Défis de la calibration traditionnelle}

La calibration traditionnelle présente plusieurs limitations majeures :

\begin{enumerate}
\item \textbf{Coût computationnel} : Chaque évaluation de la fonction objectif nécessite le calcul de $N$ volatilités implicites via inversion numérique
\item \textbf{Sensibilité à l'initialisation} : Les algorithmes peuvent converger vers des minima locaux selon le point de départ
\item \textbf{Instabilité numérique} : Les calculs d'intégrales complexes peuvent être instables dans certaines régions
\item \textbf{Temps de convergence} : La convergence peut être lente, particulièrement pour des surfaces de volatilité complexes
\end{enumerate}

Ces limitations motivent le développement de l'approche hybride que nous présentons dans la section suivante.

\section{Méthodologie Deep Learning : approche en deux étapes}

\subsection{Vue d'ensemble de l'approche}

Notre méthodologie suit la philosophie en deux étapes proposée par \citet{bayer2018deep}, adaptée spécifiquement aux exigences de la calibration du modèle de Heston sur données SPX Weekly.

\textbf{Étape 1 - Apprentissage de la fonction de pricing} : Un réseau de neurones $\mathcal{N}_\phi$ est entraîné pour approximer la fonction $f : \Theta \times \mathcal{M} \times \mathcal{T} \rightarrow \mathbb{R}^+$ qui mappe les paramètres de Heston, la moneyness et la maturité vers la volatilité implicite correspondante.

\textbf{Étape 2 - Calibration hybride} : Cette approximation neuronale remplace les évaluations coûteuses de volatilité implicite dans l'algorithme d'optimisation de Levenberg-Marquardt, accélérant drastiquement le processus de calibration.

Cette approche présente plusieurs avantages stratégiques :
\begin{itemize}
\item Préservation de la robustesse des algorithmes d'optimisation établis
\item Transparence et contrôlabilité du processus de calibration
\item Possibilité de validation par comparaison avec les méthodes traditionnelles
\item Flexibilité pour l'intégration dans les systèmes existants
\end{itemize}

\subsection{Génération des données d'entraînement}

\subsubsection{Échantillonnage des paramètres}

La génération d'un dataset d'entraînement représentatif constitue l'étape critique de notre méthodologie. Nous adoptons une stratégie d'échantillonnage sophistiquée qui garantit une couverture optimale de l'espace des paramètres tout en respectant les contraintes du modèle.

Les paramètres sont échantillonnés selon les distributions suivantes, calibrées sur l'analyse historique des calibrations SPX :

\begin{align}
\kappa &\sim \text{LogNormal}(\mu_\kappa = 0.5, \sigma_\kappa = 0.8) \text{ tronquée à } [0.1, 5.0] \\
\theta &\sim \text{Beta}(\alpha_\theta = 2, \beta_\theta = 8) \times 0.5 \\
\sigma &\sim \text{LogNormal}(\mu_\sigma = -1.2, \sigma_\sigma = 0.6) \text{ tronquée à } [0.05, 1.0] \\
\rho &\sim \text{Beta}(\alpha_\rho = 2, \beta_\rho = 5) \times 1.4 - 0.9 \\
v_0 &\sim \text{LogNormal}(\mu_{v_0} = -3.2, \sigma_{v_0} = 0.5) \text{ tronquée à } [0.01, 0.5]
\end{align}

Cette approche non-uniforme concentre l'échantillonnage dans les régions de l'espace des paramètres les plus fréquemment observées en pratique, améliorant l'efficacité de l'apprentissage.

\subsubsection{Grille de moneyness et maturités}

Pour chaque jeu de paramètres échantillonné, nous calculons les volatilités implicites sur une grille $(m, T)$ où :
\begin{itemize}
\item Moneyness : $m = K/S_0 \in [0.75, 1.25]$ avec 25 points uniformément répartis
\item Maturités : $T \in [1/365, 60/365]$ avec 20 points log-uniformément répartis
\end{itemize}

Cette grille reflète fidèlement les caractéristiques des options SPX Weekly disponibles sur le marché.

\subsubsection{Procédure de calcul des volatilités implicites}

Pour chaque triplet $(\boldsymbol{\theta}, m, T)$, la volatilité implicite est calculée selon la procédure suivante :

\begin{algorithm}[H]
\caption{Calcul de volatilité implicite Heston}
\begin{algorithmic}
\REQUIRE Paramètres $\boldsymbol{\theta}$, moneyness $m$, maturité $T$
\ENSURE Volatilité implicite $\sigma_{IV}$

\STATE // Calcul du prix Heston via FFT
\STATE $price_{Heston} \leftarrow$ HestonPriceFFT($\boldsymbol{\theta}$, $m$, $T$)

\STATE // Validation du prix
\IF{$price_{Heston} \leq 0$ OR $price_{Heston} \geq S_0$}
    \RETURN NaN
\ENDIF

\STATE // Inversion pour la volatilité implicite
\FUNCTION{ObjectiveBSPrice}{$\sigma$}
    \RETURN BlackScholesPrice($m$, $T$, $\sigma$) - $price_{Heston}$
\ENDFUNCTION

\STATE // Recherche de racine par méthode de Brent
\TRY
    \STATE $\sigma_{IV} \leftarrow$ BrentRoot(ObjectiveBSPrice, 0.001, 3.0)
\CATCH
    \RETURN NaN
\ENDTRY

\RETURN $\sigma_{IV}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Filtrage et validation qualité}

Les données générées subissent un processus de filtrage rigoureux pour éliminer les observations aberrantes :

\begin{enumerate}
\item \textbf{Filtre de validité} : Élimination des volatilités implicites non-définies (NaN) ou négatives
\item \textbf{Filtre de plausibilité} : Exclusion des volatilités < 1\% ou > 300\%
\item \textbf{Filtre d'arbitrage} : Vérification de la monotonicité approximative des calls par strike
\item \textbf{Filtre de stabilité} : Élimination des configurations de paramètres produisant des instabilités numériques
\end{enumerate}

Au final, notre dataset d'entraînement comprend 750,000 surfaces de volatilité valides, soit environ 18.75 millions de paires (input, output) individuelles.

\subsection{Architecture du réseau de neurones}

\subsubsection{Design de l'architecture}

Notre réseau de neurones $\mathcal{N}_\phi$ adopte une architecture de type feed-forward dense, optimisée pour capturer les non-linéarités complexes de la fonction de pricing de Heston.

\textbf{Architecture détaillée :}
\begin{itemize}
\item \textbf{Couche d'entrée} : 7 neurones (5 paramètres Heston + moneyness + maturité)
\item \textbf{Couches cachées} : 4 couches avec [256, 512, 256, 128] neurones respectivement
\item \textbf{Couche de sortie} : 1 neurone (volatilité implicite)
\item \textbf{Fonctions d'activation} : ReLU pour les couches cachées, sigmoïde pour la sortie
\item \textbf{Régularisation} : Dropout (taux variables) et Batch Normalization
\end{itemize}

\subsubsection{Justification du design}

Le choix architectural reflète plusieurs considérations :

\begin{enumerate}
\item \textbf{Capacité représentationnelle} : Les 4 couches cachées permettent de capturer les interactions complexes entre paramètres
\item \textbf{Évitement de l'overfitting} : L'architecture pyramidale (256→512→256→128) évite l'accumulation excessive de paramètres
\item \textbf{Stabilité numérique} : La batch normalization stabilise l'entraînement sur large dataset
\item \textbf{Contraintes de sortie} : La fonction sigmoïde garantit des volatilités positives
\end{enumerate}

\subsubsection{Preprocessing des données}

Les données d'entrée subissent une normalisation sophistiquée pour optimiser l'apprentissage :

\begin{align}
\kappa_{norm} &= \frac{\log(\kappa) - \mu_{\log \kappa}}{\sigma_{\log \kappa}} \\
\theta_{norm} &= \frac{\sqrt{\theta} - \mu_{\sqrt{\theta}}}{\sigma_{\sqrt{\theta}}} \\
\sigma_{norm} &= \frac{\log(\sigma) - \mu_{\log \sigma}}{\sigma_{\log \sigma}} \\
\rho_{norm} &= \frac{\text{atanh}(\rho/0.99) - \mu_{\text{atanh}(\rho)}}{\sigma_{\text{atanh}(\rho)}} \\
v_0_{norm} &= \frac{\sqrt{v_0} - \mu_{\sqrt{v_0}}}{\sigma_{\sqrt{v_0}}} \\
m_{norm} &= \frac{m - 1.0}{0.25} \\
T_{norm} &= \frac{\log(T) - \mu_{\log T}}{\sigma_{\log T}}
\end{align}

Ces transformations stabilisent l'entraînement en égalisant les échelles et en gérant les effets de bord.

\subsection{Procédure d'entraînement}

\subsubsection{Fonction de perte et optimisation}

La fonction de perte adoptée combine erreur quadratique et régularisation :

\begin{equation}
\mathcal{L}(\phi) = \frac{1}{N} \sum_{i=1}^{N} \left(\sigma_{IV,i}^{true} - \mathcal{N}_\phi(\boldsymbol{x}_i)\right)^2 + \lambda \|\phi\|_2^2
\end{equation}

L'optimisation utilise l'algorithme Adam \citep{kingma2014adam} avec les hyperparamètres suivants :
\begin{itemize}
\item Learning rate initial : $\alpha_0 = 0.001$
\item Paramètres de momentum : $\beta_1 = 0.9$, $\beta_2 = 0.999$
\item Scheduler ReduceLROnPlateau : patience = 10, factor = 0.5
\item Weight decay : $\lambda = 1 \times 10^{-5}$
\end{itemize}

\subsubsection{Stratégie d'entraînement}

L'entraînement suit un protocole rigoureux sur 1000 épochs maximum :

\begin{algorithm}[H]
\caption{Procédure d'entraînement}
\begin{algorithmic}
\REQUIRE Dataset $\mathcal{D}$, architecture $\mathcal{N}_\phi$
\ENSURE Réseau entraîné $\mathcal{N}_{\phi^*}$

\STATE // Division du dataset
\STATE $\mathcal{D}_{train}, \mathcal{D}_{val}, \mathcal{D}_{test} \leftarrow$ split($\mathcal{D}$, [0.7, 0.15, 0.15])

\STATE // Initialisation
\STATE $\phi_0 \leftarrow$ xavier\_uniform\_init()
\STATE best\_loss $\leftarrow +\infty$
\STATE patience\_counter $\leftarrow$ 0

\FOR{epoch = 1 to 1000}
    \STATE // Phase d'entraînement
    \STATE $\mathcal{N}_\phi$.train()
    \FOR{batch in $\mathcal{D}_{train}$}
        \STATE loss $\leftarrow$ compute\_loss(batch, $\mathcal{N}_\phi$)
        \STATE optimizer.zero\_grad()
        \STATE loss.backward()
        \STATE optimizer.step()
    \ENDFOR
    
    \STATE // Phase de validation
    \STATE $\mathcal{N}_\phi$.eval()
    \STATE val\_loss $\leftarrow$ evaluate($\mathcal{D}_{val}$, $\mathcal{N}_\phi$)
    
    \STATE // Early stopping
    \IF{val\_loss < best\_loss}
        \STATE best\_loss $\leftarrow$ val\_loss
        \STATE save\_checkpoint($\mathcal{N}_\phi$)
        \STATE patience\_counter $\leftarrow$ 0
    \ELSE
        \STATE patience\_counter += 1
        \IF{patience\_counter > 20}
            \STATE break
        \ENDIF
    \ENDIF
    
    \STATE scheduler.step(val\_loss)
\ENDFOR

\RETURN load\_best\_checkpoint()
\end{algorithmic}
\end{algorithm}

\section{Calibration hybride}

\subsection{Intégration de l'approximation neuronale}

Une fois le réseau entraîné, l'étape de calibration hybride remplace les évaluations coûteuses de volatilité implicite par des prédictions rapides du réseau neuronal. Le problème d'optimisation devient :

\begin{equation}
\hat{\boldsymbol{\theta}} = \arg\min_{\boldsymbol{\theta} \in \Theta} \sum_{i=1}^{N} w_i \left(\sigma_{IV}^{market}(K_i, T_i) - \mathcal{N}_{\phi^*}(\boldsymbol{\theta}, m_i, T_i)\right)^2
\end{equation}

Cette substitution transforme radicalement les caractéristiques computationnelles du problème :
\begin{itemize}
\item \textbf{Évaluation} : 0.15 ms par surface (vs 23.4 s traditionnellement)
\item \textbf{Gradients} : Disponibles par différentiation automatique
\item \textbf{Stabilité} : Pas d'instabilités numériques dans l'évaluation
\end{itemize}

\subsection{Algorithme de calibration optimisé}

Notre implémentation de la calibration hybride incorpore plusieurs optimisations spécifiques :

\begin{algorithm}[H]
\caption{Calibration hybride optimisée}
\begin{algorithmic}
\REQUIRE Surface de marché $\Sigma_{market}$, réseau $\mathcal{N}_{\phi^*}$
\ENSURE Paramètres calibrés $\hat{\boldsymbol{\theta}}$

\STATE // Initialisation intelligente
\STATE $\boldsymbol{\theta}_0 \leftarrow$ smart\_initialization($\Sigma_{market}$)

\STATE // Calibration primaire (réseau neuronal)
\FUNCTION{ObjectiveNN}{$\boldsymbol{\theta}$}
    \STATE $\Sigma_{pred} \leftarrow \mathcal{N}_{\phi^*}(\boldsymbol{\theta}, \boldsymbol{m}, \boldsymbol{T})$
    \RETURN $\|\Sigma_{market} - \Sigma_{pred}\|_2^2$
\ENDFUNCTION

\STATE $\hat{\boldsymbol{\theta}}_{NN} \leftarrow$ LevenbergMarquardt(ObjectiveNN, $\boldsymbol{\theta}_0$)

\STATE // Validation optionnelle (pricing exact)
\IF{validation\_required}
    \FUNCTION{ObjectiveExact}{$\boldsymbol{\theta}$}
        \STATE $\Sigma_{exact} \leftarrow$ HestonIV($\boldsymbol{\theta}, \boldsymbol{m}, \boldsymbol{T}$)
        \RETURN $\|\Sigma_{market} - \Sigma_{exact}\|_2^2$
    \ENDFUNCTION
    
    \STATE $\hat{\boldsymbol{\theta}}_{exact} \leftarrow$ LevenbergMarquardt(ObjectiveExact, $\hat{\boldsymbol{\theta}}_{NN}$)
    
    \IF{$\text{ObjectiveExact}(\hat{\boldsymbol{\theta}}_{exact}) < \text{threshold}$}
        \RETURN $\hat{\boldsymbol{\theta}}_{exact}$
    \ENDIF
\ENDIF

\RETURN $\hat{\boldsymbol{\theta}}_{NN}$
\end{algorithmic}
\end{algorithm}

\subsection{Stratégies d'initialisation}

L'initialisation des paramètres revêt une importance cruciale pour la convergence rapide. Notre approche développe une heuristique d'initialisation basée sur les caractéristiques observables de la surface de volatilité :

\begin{align}
v_0^{(0)} &= \left(\text{IV}_{ATM,short}\right)^2 \\
\theta^{(0)} &= \left(\text{IV}_{ATM,long}\right)^2 \\
\kappa^{(0)} &= \frac{2}{\text{T}_{avg}} \ln\left(\frac{\theta^{(0)}}{v_0^{(0)}}\right) \\
\rho^{(0)} &= -0.5 \times \tanh\left(\text{skew}_{short} \times 3\right) \\
\sigma^{(0)} &= 0.4 \times \sqrt{\text{vol\_of\_vol}_{empirical}}
\end{align}

où $\text{skew}_{short}$ mesure l'asymétrie des volatilités implicites à court terme et $\text{vol\_of\_vol}_{empirical}$ estime la variabilité des volatilités implicites.

\section{Validation et métriques de performance}

\subsection{Protocole de validation}

Notre protocole de validation suit une approche multi-niveaux garantissant la robustesse des résultats :

\subsubsection{Validation sur données synthétiques}

La première phase teste la capacité de récupération des paramètres sur 1000 surfaces synthétiques générées avec des paramètres connus mais distincts de l'ensemble d'entraînement.

\subsubsection{Validation sur données historiques}

La seconde phase utilise des données SPX Weekly historiques selon une division temporelle :
\begin{itemize}
\item Période d'entraînement : 01/2020 - 06/2022
\item Période de test : 07/2022 - 12/2022
\item Validation croisée : 5-fold temporelle
\end{itemize}

\subsubsection{Tests de stress}

Des tests spécifiques évaluent la robustesse dans des conditions extrêmes :
\begin{itemize}
\item Périodes de haute volatilité (VIX > 40)
\item Configurations de paramètres aux frontières de l'espace admissible
\item Surfaces de volatilité avec patterns non-standard
\end{itemize}

\subsection{Métriques de performance}

\subsubsection{Précision de calibration}

Les métriques de précision comprennent :

\begin{align}
\text{RMSE}_{IV} &= \sqrt{\frac{1}{N} \sum_{i=1}^{N} \left(\sigma_{IV,i}^{market} - \sigma_{IV,i}^{model}\right)^2} \\
\text{MAE}_{IV} &= \frac{1}{N} \sum_{i=1}^{N} \left|\sigma_{IV,i}^{market} - \sigma_{IV,i}^{model}\right| \\
\text{MAPE}_{IV} &= \frac{1}{N} \sum_{i=1}^{N} \frac{\left|\sigma_{IV,i}^{market} - \sigma_{IV,i}^{model}\right|}{\sigma_{IV,i}^{market}} \times 100\%
\end{align}

\subsubsection{Précision des paramètres}

Pour les tests sur données synthétiques :

\begin{align}
\text{Bias}_j &= \frac{1}{M} \sum_{k=1}^{M} \left(\theta_{j,k}^{estimated} - \theta_{j,k}^{true}\right) \\
\text{RMSE}_j &= \sqrt{\frac{1}{M} \sum_{k=1}^{M} \left(\theta_{j,k}^{estimated} - \theta_{j,k}^{true}\right)^2}
\end{align}

\subsubsection{Performance computationnelle}

Les métriques temporelles incluent :
\begin{itemize}
\item Temps de calibration par surface de volatilité
\item Temps de calcul des grecques par option
\item Utilisation mémoire peak et moyenne
\item Débit (surfaces calibrées par seconde)
\end{itemize}

\subsection{Tests statistiques}

La significativité des améliorations est validée par :

\subsubsection{Test de Diebold-Mariano}

Ce test compare la précision prédictive de deux méthodes de forecasting. Pour les erreurs de calibration $e_{1,t}$ et $e_{2,t}$ des méthodes traditionnelle et Deep Learning :

\begin{equation}
DM = \frac{\bar{d}}{\sqrt{\widehat{\text{Var}}(\bar{d})}} \sim \mathcal{N}(0,1)
\end{equation}

où $\bar{d} = \frac{1}{T}\sum_{t=1}^{T} d_t$ et $d_t = L(e_{1,t}) - L(e_{2,t})$ avec $L(\cdot)$ une fonction de perte.

\subsubsection{Tests de significativité appariés}

Tests de Wilcoxon signed-rank pour la comparaison non-paramétrique des erreurs, et tests t appariés pour les comparaisons paramétriques.

\section{Calcul des sensibilités (grecques)}

\subsection{Différentiation automatique}

Un avantage majeur de l'approche neuronale réside dans la disponibilité naturelle des gradients via différentiation automatique. Les sensibilités aux paramètres s'obtiennent directement :

\begin{equation}
\frac{\partial \sigma_{IV}}{\partial \theta_j} = \frac{\partial \mathcal{N}_{\phi^*}}{\partial \theta_j}(\boldsymbol{\theta}, m, T)
\end{equation}

Cette capacité permet le calcul simultané des prix et sensibilités sans coût computationnel additionnel significatif.

\subsection{Grecques traditionnelles}

Les grecques traditionnelles (Delta, Gamma, Vega, Theta, Rho) sont calculées par différentiation numérique des prix obtenus via l'approximation neuronale :

\begin{align}
\Delta &= \frac{\partial C}{\partial S} \approx \frac{C(S+h) - C(S-h)}{2h} \\
\Gamma &= \frac{\partial^2 C}{\partial S^2} \approx \frac{C(S+h) - 2C(S) + C(S-h)}{h^2} \\
\text{Vega} &= \frac{\partial C}{\partial \sigma_{IV}} \text{ (disponible analytiquement)}
\end{align}

\subsection{Validation des sensibilités}

La précision des grecques est validée par comparaison avec :
\begin{itemize}
\item Calculs analytiques Black-Scholes pour les cas limites
\item Différentiation numérique de haute précision sur le modèle de Heston exact
\item Techniques de Monte Carlo avec antithetic variates
\end{itemize}

\section{Considérations d'implémentation}

\subsection{Infrastructure technique}

Notre implémentation utilise :
\begin{itemize}
\item \textbf{Framework} : PyTorch 1.12 avec CUDA 11.6
\item \textbf{Hardware} : GPU NVIDIA Tesla V100 (32GB VRAM)
\item \textbf{Optimisation} : Mixed precision training (FP16/FP32)
\item \textbf{Stockage} : Format HDF5 pour les datasets volumineux
\end{itemize}

\subsection{Optimisations de performance}

Plusieurs optimisations améliorent l'efficacité :

\begin{enumerate}
\item \textbf{Vectorisation} : Traitement par batch des évaluations
\item \textbf{Compilation JIT} : TorchScript pour l'accélération des inférences
\item \textbf{Quantization} : Réduction de précision pour les modèles en production
\item \textbf{Model serving} : Déploiement via TorchServe pour les applications temps réel
\end{enumerate}

\subsection{Monitoring et diagnostics}

Un système de monitoring intégré surveille :
\begin{itemize}
\item Dérive des performances sur données en temps réel
\item Distribution des erreurs par région de l'espace des paramètres
\item Détection d'anomalies dans les calibrations
\item Métriques de qualité des grecques
\end{itemize}

\section{Conclusion méthodologique}

Cette méthodologie représente une synthèse sophistiquée des meilleures pratiques en Deep Learning appliqué à la finance quantitative. L'approche en deux étapes préserve la robustesse et la transparence des méthodes traditionnelles tout en exploitant pleinement les avantages computationnels des techniques d'apprentissage automatique.

Les innovations clés incluent :
\begin{itemize}
\item Stratégie d'échantillonnage des paramètres informée par les observations empiriques
\item Architecture neuronale optimisée pour la fonction de pricing de Heston
\item Procédures de validation multi-niveaux garantissant la robustesse
\item Integration transparente dans les workflows de calibration existants
\end{itemize}

La validation expérimentale de cette méthodologie, présentée dans le chapitre suivant, confirme sa supériorité par rapport aux approches traditionnelles sur tous les critères de performance pertinents.
